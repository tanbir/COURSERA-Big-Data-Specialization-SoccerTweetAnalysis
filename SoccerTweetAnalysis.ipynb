{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and create a new SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the country CSV file into an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Afghanistan, AFG',\n",
       " 'Albania, ALB',\n",
       " 'Algeria, ALG',\n",
       " 'American Samoa, ASA',\n",
       " 'Andorra, AND',\n",
       " 'Angola, ANG',\n",
       " 'Anguilla, AIA']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_lines = sc.textFile('file:///home/cloudera/Downloads/coursera-master/big-data-3/final-project/country-list.csv')\n",
    "country_lines.take(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert each line into a pair of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Afghanistan', ' AFG'],\n",
       " ['Albania', ' ALB'],\n",
       " ['Algeria', ' ALG'],\n",
       " ['American Samoa', ' ASA'],\n",
       " ['Andorra', ' AND'],\n",
       " ['Angola', ' ANG'],\n",
       " ['Anguilla', ' AIA']]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_lines.collect()\n",
    "country_lines.map(lambda line : line.split(\",\")).take(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert each pair of words into a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Afghanistan', ' AFG'),\n",
       " ('Albania', ' ALB'),\n",
       " ('Algeria', ' ALG'),\n",
       " ('American Samoa', ' ASA'),\n",
       " ('Andorra', ' AND'),\n",
       " ('Angola', ' ANG'),\n",
       " ('Anguilla', ' AIA')]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_tuples = country_lines.map(lambda line : (line.split(\",\")[0], \n",
    "                                                  line.split(\",\")[1]))\n",
    "country_tuples.take(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the DataFrame, look at schema and contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country: string (nullable = true)\n",
      " |-- code: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(country='Afghanistan', code=' AFG'),\n",
       " Row(country='Albania', code=' ALB'),\n",
       " Row(country='Algeria', code=' ALG')]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countryDF = sqlContext.createDataFrame(country_tuples, [\"country\", \"code\"])\n",
    "countryDF.printSchema()\n",
    "countryDF.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read tweets CSV file into RDD of lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13995"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = sc.textFile('file:///home/cloudera/Downloads/coursera-master/big-data-3/final-project/tweets.csv')\n",
    "tweets.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the data: Remove the empty tweets using filter() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13391"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_tweets = tweets.filter(lambda a : len(a) > 0)\n",
    "filtered_tweets.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform WordCount on the cleaned tweet texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 3292),\n",
       " ('https://t.co/fQftAwGAad', 1),\n",
       " ('mobile', 1),\n",
       " ('#FridayNightTouchdown', 1),\n",
       " ('circle', 7),\n",
       " ('#thfc', 2),\n",
       " ('reinstated', 4)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = filtered_tweets.flatMap(lambda line : line.split(\" \")) \\\n",
    "    .map(lambda word : (word, 1)) \\\n",
    "    .reduceByKey(lambda a, b : (a + b))\n",
    "word_counts.take(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the DataFrame of tweet word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- word: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(word='', count=3292),\n",
       " Row(word='https://t.co/fQftAwGAad', count=1),\n",
       " Row(word='mobile', count=1),\n",
       " Row(word='#FridayNightTouchdown', count=1),\n",
       " Row(word='circle', count=7),\n",
       " Row(word='#thfc', count=2),\n",
       " Row(word='reinstated', count=4)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsDF = sqlContext.createDataFrame(word_counts, [\"word\", \"count\"])\n",
    "tweetsDF.printSchema()\n",
    "tweetsDF.take(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join the country and tweet DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(country='Thailand', code=' THA', word='Thailand', count=1),\n",
       " Row(country='Iceland', code=' ISL', word='Iceland', count=2),\n",
       " Row(country='Mexico', code=' MEX', word='Mexico', count=1),\n",
       " Row(country='Wales', code=' WAL', word='Wales', count=19),\n",
       " Row(country='Denmark', code=' DEN', word='Denmark', count=1),\n",
       " Row(country='India', code=' IND', word='India', count=4),\n",
       " Row(country='Portugal', code=' POR', word='Portugal', count=8)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joinedDF = countryDF.join(tweetsDF, countryDF.country == tweetsDF.word)\n",
    "joinedDF.take(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Number of distinct countries mentioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_countries = joinedDF.select(\"country\").distinct()\n",
    "distinct_countries.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Number of countries mentioned in tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(sum(count)=397)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "\n",
    "joinedDF.agg(sum(\"count\")).first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Top three countries and their counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-------+-----+\n",
      "|country|code|   word|count|\n",
      "+-------+----+-------+-----+\n",
      "| Norway| NOR| Norway|   52|\n",
      "|Nigeria| NGA|Nigeria|   49|\n",
      "| France| FRA| France|   42|\n",
      "+-------+----+-------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "descSorted = joinedDF.sort(desc(\"count\"))\n",
    "descSorted.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. # times France was mentioned in a tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Most mentioned: Kenya, Wales, Netherlands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+-----------+-----+\n",
      "|    country|code|       word|count|\n",
      "+-----------+----+-----------+-----+\n",
      "|      Wales| WAL|      Wales|   19|\n",
      "|Netherlands| NED|Netherlands|   13|\n",
      "|      Kenya| KEN|      Kenya|    3|\n",
      "+-----------+----+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Table 2: counts for Wales, Iceland, and Japan.\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "selected = joinedDF.where((col(\"country\")==\"Wales\") | \n",
    "                          (col(\"country\")==\"Netherlands\") |\n",
    "                          (col(\"country\")==\"Kenya\"))\n",
    "selected.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Average # times a country is mentioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(avg(count)=9.022727272727273)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "joinedDF.agg(avg('count')).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
